{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPSiLSdvkBR0TFTyK+AO7n4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xJeZNjbkxtT2"},"outputs":[],"source":["# Image denoiser\n","# Copyright Andriy Melnykov 2025\n","\n","# Images are TIFF, 16-bit RGB\n","\n","# --- 1. paths (edit!) ---------------------------------------------------------\n","MODEL_PATH = \"/content/drive/MyDrive/Colab_Data/train_16.keras\"\n","IN_TIF     = \"/content/drive/MyDrive/Colab_Data/test_image.tiff\"\n","OUT_TIF    = \"/content/drive/MyDrive/Colab_Data/test_image_filtered_16.tiff\"\n","\n","# --- 2. drive & libs ----------------------------------------------------------\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install tifffile  # fast 16‑bit IO\n","!pip install imagecodecs\n","\n","import numpy as np\n","import tifffile as tiff\n","import math\n","import tqdm\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","print(\"Libraries loaded\")\n","\n","# --- 3. load model (no compile needed for inference) --------------------------\n","model = keras.models.load_model(MODEL_PATH, compile=False)\n","PATCH_IN   = 128\n","PATCH_KEEP = 64            # central crop returned to mosaic\n","STRIDE     = 32\n","\n","# Hann window for soft overlap‑add (same size as KEEP region)\n","win1d = np.hanning(PATCH_KEEP)\n","window = np.outer(win1d, win1d).astype('float32') + 1e-6  # avoid /0 later\n","window = window[..., None]                                # add channel dim\n","\n","# --- 4. read & normalise full frame ------------------------------------------\n","img16 = tiff.imread(IN_TIF)                 # (H,W,3) uint16\n","img   = img16.astype('float32') / 65535.0   # 0‑1\n","\n","print(\"Image loaded\")\n","\n","H, W, C = img.shape\n","pad_tile = (PATCH_IN - PATCH_KEEP) // 2          # 32 px\n","pad_img = PATCH_IN\n","pad_cfg_tile = ((pad_tile, pad_tile), (pad_tile, pad_tile), (0,0))\n","pad_cfg_img = ((pad_img, pad_img), (pad_img, pad_img), (0,0))\n","img_padded = np.pad(img, pad_cfg_img, mode='reflect')\n","Hpad, Wpad = img_padded.shape[:2]\n","\n","# allocate output & weight accumulators\n","out  = np.zeros_like(img_padded, dtype='float32')\n","wmap = np.zeros_like(img_padded, dtype='float32')\n","\n","# tile ranges\n","ys = range(0, Hpad - PATCH_IN + 1, STRIDE)\n","xs = range(0, Wpad - PATCH_IN + 1, STRIDE)\n","\n","# --- 5. process tiles in small batches ---------------------------------------\n","batch = []\n","coords = []\n","BATCH_SIZE = 32\n","\n","def flush_batch():\n","    if not batch: return\n","    pred = model.predict(np.stack(batch), verbose=0)\n","    for (y,x), p in zip(coords, pred):\n","        # central crop\n","        p_crop = p[pad_tile:pad_tile+PATCH_KEEP, pad_tile:pad_tile+PATCH_KEEP] * window\n","        oy, ox = y+pad_tile, x+pad_tile\n","        out[oy:oy+PATCH_KEEP, ox:ox+PATCH_KEEP] += p_crop\n","        wmap[oy:oy+PATCH_KEEP, ox:ox+PATCH_KEEP] += window\n","    batch.clear(); coords.clear()\n","\n","for y in tqdm.tqdm(ys, desc=\"Tiles\"):\n","    for x in xs:\n","        patch = img_padded[y:y+PATCH_IN, x:x+PATCH_IN]\n","        batch.append(patch)\n","        coords.append((y,x))\n","        if len(batch) == BATCH_SIZE:\n","            flush_batch()\n","flush_batch()   # leftovers\n","\n","# --- 6. normalise by weight map & crop back to original size -----------------\n","wmap[wmap == 0] = 1e-6\n","out /= wmap\n","out_clipped = np.clip(out, 0.0, 1.0)\n","denoised = out_clipped[pad_img:pad_img+H, pad_img:pad_img+W]\n","\n","# --- 7. save 16‑bit TIFF ------------------------------------------------------\n","tiff.imwrite(OUT_TIF, (denoised*65535).astype('uint16'))\n","print(\"Image saved:\", OUT_TIF)"]}]}